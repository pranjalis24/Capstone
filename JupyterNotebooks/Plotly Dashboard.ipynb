{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b8c3530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dash_bootstrap_components\n",
      "  Downloading dash_bootstrap_components-1.6.0-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: dash>=2.0.0 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash_bootstrap_components) (2.16.1)\n",
      "Requirement already satisfied: Flask<3.1,>=1.0.4 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash_bootstrap_components) (1.1.2)\n",
      "Requirement already satisfied: Werkzeug<3.1 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash_bootstrap_components) (2.0.3)\n",
      "Requirement already satisfied: plotly>=5.0.0 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash_bootstrap_components) (5.6.0)\n",
      "Requirement already satisfied: dash-html-components==2.0.0 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash_bootstrap_components) (2.0.0)\n",
      "Requirement already satisfied: dash-core-components==2.0.0 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash_bootstrap_components) (2.0.0)\n",
      "Requirement already satisfied: dash-table==5.0.0 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash_bootstrap_components) (5.0.0)\n",
      "Requirement already satisfied: importlib-metadata in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash_bootstrap_components) (4.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.1.1 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash_bootstrap_components) (4.5.0)\n",
      "Requirement already satisfied: requests in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash_bootstrap_components) (2.27.1)\n",
      "Requirement already satisfied: retrying in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash_bootstrap_components) (1.3.4)\n",
      "Requirement already satisfied: nest-asyncio in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash_bootstrap_components) (1.5.5)\n",
      "Requirement already satisfied: setuptools in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from dash>=2.0.0->dash_bootstrap_components) (61.2.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from Flask<3.1,>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (2.11.3)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from Flask<3.1,>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (2.0.1)\n",
      "Requirement already satisfied: click>=5.1 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from Flask<3.1,>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (8.0.4)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from plotly>=5.0.0->dash>=2.0.0->dash_bootstrap_components) (8.0.1)\n",
      "Requirement already satisfied: six in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from plotly>=5.0.0->dash>=2.0.0->dash_bootstrap_components) (1.16.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from importlib-metadata->dash>=2.0.0->dash_bootstrap_components) (3.7.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from requests->dash>=2.0.0->dash_bootstrap_components) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from requests->dash>=2.0.0->dash_bootstrap_components) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from requests->dash>=2.0.0->dash_bootstrap_components) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from requests->dash>=2.0.0->dash_bootstrap_components) (3.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/sanyuja/opt/anaconda3/lib/python3.9/site-packages (from Jinja2>=2.10.1->Flask<3.1,>=1.0.4->dash>=2.0.0->dash_bootstrap_components) (2.0.1)\n",
      "Downloading dash_bootstrap_components-1.6.0-py3-none-any.whl (222 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.5/222.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: dash_bootstrap_components\n",
      "Successfully installed dash_bootstrap_components-1.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install dash_bootstrap_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf1b87",
   "metadata": {},
   "source": [
    "Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8084b23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.__version__\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "import dash\n",
    "from dash import dcc, html, Input, Output\n",
    "import dash_bootstrap_components as dbc\n",
    "import plotly.express as px\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b1c895",
   "metadata": {},
   "source": [
    "Let's read all the necsssary csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e8e7c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "orders_df = pd.read_csv('cleaned_orders_P.csv')\n",
    "lineitem_df = pd.read_csv('Line_item.csv')\n",
    "customer_df = pd.read_csv('customer.csv')\n",
    "merged_df = pd.read_csv(\"merged_data_o.csv\")\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d897c1",
   "metadata": {},
   "source": [
    "Performing calculations for the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02384984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the specified columns to datetime format\n",
    "datetime_columns = ['Paid_at', 'Fulfilled_at', 'Created_at', 'Cancelled_at']\n",
    "\n",
    "for col in datetime_columns:\n",
    "    orders_df[col] = pd.to_datetime(orders_df[col], format='%Y-%m-%d %H:%M:%S', errors='coerce', utc=True)\n",
    "\n",
    "# Verify the datatype conversion by printing the dtypes of these columns\n",
    "converted_dtypes = orders_df[datetime_columns].dtypes\n",
    "#print(converted_dtypes)\n",
    "\n",
    "orders_df['Year_Month'] = orders_df['Paid_at'].dt.to_period('M')\n",
    "monthly_sales = orders_df.groupby('Year_Month')['Total'].sum().reset_index()\n",
    "\n",
    "merged_df = pd.merge(customer_df, orders_df, on='Order_ID')\n",
    "\n",
    "#print(merged_df.head(5))\n",
    "\n",
    "sales_by_country = merged_df.groupby('Billing_Country')['Total'].sum()\n",
    "\n",
    "highest_billing_country = sales_by_country.idxmax()\n",
    "highest_billing_value = sales_by_country.max()\n",
    "#print(f\"The country with the highest billing is {highest_billing_country} with a total sales of {highest_billing_value:.2f}\")\n",
    "\n",
    "# Sort the sales_by_country in descending order and select the top 10\n",
    "top_10_sales_by_country = sales_by_country.sort_values(ascending=False).head(10)\n",
    "\n",
    "# Convert to DataFrame for Plotly\n",
    "top_10_df = top_10_sales_by_country.reset_index()\n",
    "top_10_df.columns = ['Country', 'Total Sales']\n",
    "\n",
    "# Group by 'Billing Country' and 'Billing Province' and calculate total sales\n",
    "sales_by_country_province = merged_df.groupby(['Billing_Country', 'Billing_Province'])['Total'].sum().reset_index()\n",
    "\n",
    "# Sort the results to identify top regions\n",
    "sales_by_country_province_sorted = sales_by_country_province.sort_values(by='Total', ascending=False)\n",
    "\n",
    "# Assuming sales_by_country_province_sorted is already created and sorted\n",
    "# Explicitly creating a copy of the DataFrame slice\n",
    "top_10_regions = sales_by_country_province_sorted.head(10).copy()\n",
    "\n",
    "# Create a new column 'Region' for plotting that combines 'Billing_Country' and 'Billing_Province'\n",
    "top_10_regions['Region'] = top_10_regions['Billing_Country'] + ' - ' + top_10_regions['Billing_Province']\n",
    "\n",
    "# Get unique provinces\n",
    "provinces_list = merged_df['Billing_Province'].unique()\n",
    "\n",
    "#lineitem type\n",
    "merged_df_o = pd.read_csv(\"merged_data_o.csv\")\n",
    "line = pd.read_csv(\"/Users/sanyuja/plotlysales/Line_item.csv\")\n",
    "import re\n",
    "\n",
    "service_keywords = [\"Shipping Protection\", \"Sustainability & Coverage\", \"Onward VIP Protection\"]\n",
    "\n",
    "gift_cards = [\"Gift Card\", \"E-Gift Card\"]\n",
    "\n",
    "product = [\"The Gigi\", \"The Brenna\", \"The Slide\", \"The Sandal\",\n",
    "           \"The D'orsay\", \"The Pashionista\", \"The Miranda\", \"The Adrianna\",\n",
    "           \"The Slingback\", \"The Pump\", \"The Bootie\", \"The Boot\", \"Sale\"]\n",
    "\n",
    "# Existing regex for general combos\n",
    "regex_combos = r'(?:\\+|-\\sSize\\s[0-9]|-\\sFinal\\sSale|-\\s[0-9]-[0-9]\\.5|-\\s[0-9]+(?:-[0-9]+)?\\.[0-9]+)'\n",
    "\n",
    "# Specific regex patterns for items categorized under shoes or accessories within combos\n",
    "regex_shoes = r'(.+?) - (\\d+)-(\\d+\\.\\d+)'\n",
    "regex_accessories_kit = r'(.+?\\bkit\\b.+) - (\\d+)-(\\d+\\.\\d+)'\n",
    "\n",
    "\n",
    "def categorize_lineitem(name):\n",
    "    # First, check for services and gift cards\n",
    "    if any(service_keyword.lower() in name.lower() for service_keyword in service_keywords):\n",
    "        return 'Services'\n",
    "    if 'Gift' in name:\n",
    "        return 'Gift Cards'\n",
    "    # Next, check for specific combo patterns to classify as shoes or accessories\n",
    "    elif re.search(regex_accessories_kit, name, re.IGNORECASE):\n",
    "        return 'Accessories'\n",
    "    elif re.search(regex_shoes, name, re.IGNORECASE):\n",
    "        return 'Shoes'\n",
    "    # Check general combos with existing regex\n",
    "    elif re.search(regex_combos, name, re.IGNORECASE):\n",
    "        return 'Combos'\n",
    "    # Check for general product mentions\n",
    "    elif any(pr.lower() in name.lower() for pr in product):\n",
    "        return 'Shoes'\n",
    "    else:\n",
    "        return 'Accessories'  # Default category if none of the above\n",
    "\n",
    "\n",
    "# Example application (assuming merged_df is already defined)\n",
    "line['Item_type'] = line['Lineitem_name'].apply(categorize_lineitem)\n",
    "#print(line[['Lineitem_name', 'Item_type']].head())\n",
    "\n",
    "# Keep only the specified columns\n",
    "columns_to_keep = [\n",
    "    'Order_ID', 'Lineitem_quantity', 'Lineitem_name',\n",
    "    'Lineitem_price', 'Item_type'\n",
    "]\n",
    "line = line[columns_to_keep]\n",
    "#print(line.columns)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "# merged_df.to_csv('aa.csv', index=False)\n",
    "import re\n",
    "\n",
    "service_keywords = [\"Shipping Protection\", \"Sustainability & Coverage\", \"Onward VIP Protection\"]\n",
    "\n",
    "gift_cards = [\"Gift Card\", \"E-Gift Card\"]\n",
    "\n",
    "product = [\"The Gigi\", \"The Brenna\", \"The Slide\", \"The Sandal\",\n",
    "           \"The D'orsay\", \"The Pashionista\", \"The Miranda\", \"The Adrianna\",\n",
    "           \"The Slingback\", \"The Pump\", \"The Bootie\", \"The Boot\", \"Sale\"]\n",
    "\n",
    "# Existing regex for general combos\n",
    "regex_combos = r'(?:\\+|-\\sSize\\s[0-9]|-\\sFinal\\sSale|-\\s[0-9]-[0-9]\\.5|-\\s[0-9]+(?:-[0-9]+)?\\.[0-9]+)'\n",
    "\n",
    "# Specific regex patterns for items categorized under shoes or accessories within combos\n",
    "regex_shoes = r'(.+?) - (\\d+)-(\\d+\\.\\d+)'\n",
    "regex_accessories_kit = r'(.+?\\bkit\\b.+) - (\\d+)-(\\d+\\.\\d+)'\n",
    "\n",
    "\n",
    "def categorize_lineitem(name):\n",
    "    # First, check for services and gift cards\n",
    "    if any(service_keyword.lower() in name.lower() for service_keyword in service_keywords):\n",
    "        return 'Services'\n",
    "    if 'Gift' in name:\n",
    "        return 'Gift Cards'\n",
    "    # Next, check for specific combo patterns to classify as shoes or accessories\n",
    "    elif re.search(regex_accessories_kit, name, re.IGNORECASE):\n",
    "        return 'Accessories'\n",
    "    elif re.search(regex_shoes, name, re.IGNORECASE):\n",
    "        return 'Shoes'\n",
    "    # Check general combos with existing regex\n",
    "    elif re.search(regex_combos, name, re.IGNORECASE):\n",
    "        return 'Combos'\n",
    "    # Check for general product mentions\n",
    "    elif any(pr.lower() in name.lower() for pr in product):\n",
    "        return 'Shoes'\n",
    "    else:\n",
    "        return 'Accessories'  # Default category if none of the above\n",
    "\n",
    "\n",
    "# Example application (assuming merged_df is already defined)\n",
    "line['Item_type'] = line['Lineitem_name'].apply(categorize_lineitem)\n",
    "#print(line[['Lineitem_name', 'Item_type']].head())\n",
    "\n",
    "# Keep only the specified columns\n",
    "columns_to_keep = [\n",
    "    'Order_ID', 'Lineitem_quantity', 'Lineitem_name',\n",
    "    'Lineitem_price', 'Item_type'\n",
    "]\n",
    "line = line[columns_to_keep]\n",
    "#print(line.columns)\n",
    "\n",
    "# Optionally, save the DataFrame to a CSV file\n",
    "# merged_df.to_csv('aa.csv', index=False)\n",
    "# Identify unique lineitem_type values\n",
    "unique_types = line['Item_type'].unique()\n",
    "#print(unique_types)\n",
    "\n",
    "#Revenue by quarter\n",
    "\n",
    "data = pd.read_csv(\"merged_data.csv\", low_memory=False)\n",
    "\n",
    "\n",
    "column_to_check = 'Financial Status'\n",
    "data = data.dropna(subset=[column_to_check])\n",
    "\n",
    "\n",
    "# Convert 'Created at' column to datetime format with dayfirst=True\n",
    "data['Created at'] = pd.to_datetime(data['Created at'], dayfirst=True)\n",
    "\n",
    "# Sort the DataFrame by 'Created at'\n",
    "data = data.sort_values(by='Created at')\n",
    "\n",
    "# Forward fill missing values in 'Paid at' column based on 'Created at'\n",
    "data['Paid at'] = data['Paid at'].ffill()\n",
    "\n",
    "# Verify if any missing values remain in 'Paid at' column\n",
    "#print(\"Remaining missing values in 'Paid at' column:\", data['Paid at'].isna().sum())\n",
    "\n",
    "data.drop(columns=[\n",
    "    'Financial Status', 'Fulfillment Status', 'Currency', 'Shipping Method', 'Lineitem compare at price', 'Lineitem sku',\n",
    "    'Lineitem requires shipping', 'Lineitem taxable', 'Lineitem fulfillment status', 'Billing Street', 'Billing Address1', 'Billing Address2', 'Billing Company',\n",
    "    'Billing City', 'Lineitem quantity', 'Lineitem name', 'Lineitem price', 'Billing Zip', 'Billing Province', 'Billing Country', 'Billing Phone',\n",
    "    'Shipping Name', 'Shipping Street', 'Shipping Address1', 'Shipping Address2', 'Shipping Company', 'Shipping City', 'Shipping Zip',\n",
    "    'Shipping Province',\n",
    "    'Shipping Country',\n",
    "    'Shipping Phone',\n",
    "    'Notes',\n",
    "    'Note Attributes',\n",
    "    'Payment Method',\n",
    "    'Payment Reference',\n",
    "    'Vendor',\n",
    "    'Id',\n",
    "    'Tags',\n",
    "    'Risk Level',\n",
    "    'Source',\n",
    "    'Lineitem discount',\n",
    "    'Tax 1 Name',\n",
    "    'Tax 1 Value',\n",
    "    'Tax 2 Name',\n",
    "    'Tax 2 Value',\n",
    "    'Tax 3 Name',\n",
    "    'Tax 3 Value',\n",
    "    'Tax 4 Name',\n",
    "    'Tax 4 Value',\n",
    "    'Tax 5 Name',\n",
    "    'Tax 5 Value',\n",
    "    'Phone',\n",
    "    'Receipt Number',\n",
    "    'Duties',\n",
    "    'Billing Province Name',\n",
    "    'Shipping Province Name',\n",
    "    'Payment ID',\n",
    "    'Payment Terms Name',\n",
    "    'Next Payment Due At',\n",
    "    'Payment References'\n",
    "], inplace=True)\n",
    "\n",
    "column_name_mapping = {'Name': 'OrderID'}\n",
    "\n",
    "data.rename(columns=column_name_mapping, inplace=True)\n",
    "data.loc[:, 'Revenue'] = data['Total'] - data['Refunded Amount']\n",
    "desired_order = [\n",
    "    'OrderID',\n",
    "    'Billing Name',\n",
    "    'Email',\n",
    "    'Paid at',\n",
    "    'Discount Amount',\n",
    "    'Subtotal',\n",
    "    'Shipping',\n",
    "    'Taxes',\n",
    "    'Total',\n",
    "    'Refunded Amount',\n",
    "    'Revenue',\n",
    "    'Discount Code',\n",
    "    'Accepts Marketing'\n",
    "]\n",
    "data = data[desired_order]\n",
    "\n",
    "# data['Paid at'] = pd.to_datetime(data['Paid at'], format='%d-%m-%Y %H:%M')\n",
    "\n",
    "data['Paid at'] = pd.to_datetime(data['Paid at'], format='%d-%m-%Y %H:%M', errors='coerce')\n",
    "\n",
    "# Extract the date part from the datetime and overwrite the column with it\n",
    "data['Paid at'] = data['Paid at'].dt.date\n",
    "\n",
    "# For Customer Analysis\n",
    "#CU = data.copy()\n",
    "\n",
    "# Assuming 'data' is your DataFrame\n",
    "data = data.sort_values(by=[\"Email\", \"Paid at\"])\n",
    "\n",
    "data = data.dropna(subset = [\"Email\"])\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert 'Paid at' column to datetime\n",
    "df['Paid at'] = pd.to_datetime(df['Paid at'])\n",
    "\n",
    "# Sort DataFrame by 'Email' and 'Paid at'\n",
    "df.sort_values(by=['Email', 'Paid at'], inplace=True)\n",
    "\n",
    "# Group by 'Email' and assign order numbers\n",
    "df['Order Number'] = df.groupby('Email').cumcount() + 1\n",
    "\n",
    "# Filter out customers who have their first order between October 2023 to Jan 2024\n",
    "filtered_df = df[~((df['Paid at'] >= '2023-10-01') & (df['Order Number'] == 1))]\n",
    "\n",
    "# filtered_df\n",
    "# Count the total number of unique customers who made purchases\n",
    "total_customers = len(filtered_df['Email'].unique())\n",
    "\n",
    "# Count the number of customers who made repeat purchases (order number > 1)\n",
    "repeat_customers = len(filtered_df[filtered_df['Order Number'] > 1]['Email'].unique())\n",
    "\n",
    "# Calculate retention rate\n",
    "retention_rate = (repeat_customers / total_customers) * 100\n",
    "\n",
    "#print(\"Total Customers:\", total_customers)\n",
    "#print(\"Repeat Customers:\", repeat_customers)\n",
    "#print(\"Retention Rate: {:.2f}%\".format(retention_rate))\n",
    "\n",
    "# Extract quarter and year from 'Paid at' column\n",
    "df['Quarter'] = df['Paid at'].dt.to_period('Q')\n",
    "#filtered_df['Quarter'] = filtered_df['Paid at'].dt.to_period('Q')\n",
    "\n",
    "# Group by quarter and count unique customers\n",
    "customers_per_quarter = df.groupby('Quarter')['Email'].nunique()\n",
    "\n",
    "total_revenue = df.groupby('Quarter')['Total'].nunique() #nunique() #sum().reset_index()\n",
    "#total_revenue['Quarter'] = total_revenue['Quarter'].astype(str)\n",
    "\n",
    "#print(df['Quarter'].head(5))\n",
    "#print(total_revenue.head(5))\n",
    "#SUBSET OF ORDERS_DF(selective columns only)\n",
    "\n",
    "Or1 = orders_df[['Order_ID', 'Email', 'Paid_at', 'Total', 'Refunded_Amount', 'Discount_Amount']]\n",
    "\n",
    "# Revenue Computation\n",
    "Or1['Revenue'] = Or1['Total'] - Or1['Refunded_Amount']\n",
    "\n",
    "Or1 = Or1.sort_values(by=[\"Revenue\", \"Paid_at\"], ascending=False)\n",
    "\n",
    "# Extract month and year from 'Paid_at' column\n",
    "Or1['YearQuarter'] = Or1['Paid_at'].dt.to_period('Q')\n",
    "\n",
    "# Group by YearQuarter and sum the 'Revenue' column\n",
    "quarterly_revenue = Or1.groupby('YearQuarter')['Revenue'].sum().reset_index()\n",
    "\n",
    "# Sort the quarters in chronological order\n",
    "quarterly_revenue = quarterly_revenue.sort_values(by='YearQuarter')\n",
    "\n",
    "# Convert Period object to string for plotting\n",
    "quarterly_revenue['YearQuarter'] = quarterly_revenue['YearQuarter'].astype(str)\n",
    "\n",
    "#item type dashboard\n",
    "\n",
    "# Color map for the second section\n",
    "color_map = {\n",
    "    'Forest Velvet': '#228B22',  # Forest Green\n",
    "    'Coal Leather': '#333333',  # Dark grey, close to black\n",
    "    'Whiskey Leather': '#d29062',  # A warm, medium brown\n",
    "    'Coal Knit': '#363636',  # Dark grey, slightly lighter than Coal\n",
    "    'Sand Patent Rhinestone': '#c2b280',  # Light brown, approximation\n",
    "    'Butter': '#fffacd',  # Light creamy yellow\n",
    "    'Whiskey Knit': '#d29062',  # Similar to Whiskey Leather\n",
    "    'White Leather': '#ffffff',\n",
    "    'Taupe Blush Leather Stud': '#b38b6d',  # Taupe with pinkish hue\n",
    "    'Coal Leather Stud': '#333333',  # Same as Coal Leather\n",
    "    'Taupe Blush': '#b38b6d',  # Similar to Taupe Blush Leather Stud\n",
    "    'Storm': '#71797E',  # Grey with a hint of blue\n",
    "    'White Satin Lace': '#fffff0',  # Ivory, close to White Satin\n",
    "    'Storm Suede': '#4F4F4F',  # Greyish-black\n",
    "    'Sand Braid': '#c2b280',  # Similar to Sand Patent\n",
    "    'Sand Leather': '#f1c27d',  # Light brown-yellow\n",
    "    'Storm Knit': '#b0e0e6',  # Powder blue, as requested\n",
    "    'Whiskey': '#d29062',  # Same as Whiskey Leather\n",
    "    'Coal': '#333333',  # Coal black\n",
    "    'Latte Leather': '#c5a883',  # Similar to Latte\n",
    "    'Sand Raffia': '#c2b280',  # Similar to Sand Braid\n",
    "    'Walnut': '#773f1a',  # Dark brown\n",
    "    'Latte': '#c5a883',\n",
    "    'Walnut Patent': '#773f1a',  # Similar to Walnut\n",
    "    'Orchid Braid': '#da70d6',  # Similar to Orchid\n",
    "    'Sand Knit': '#8b4513',  # Brownish, as requested\n",
    "    'Whiskey Braid': '#d29062',  # Similar to Whiskey\n",
    "    'Sand': '#f4a460',  # Sandy brown\n",
    "    'Latte Knit': '#c5a883',  # Same as Latte, with knit pattern implied\n",
    "    'Coal Patent Bow': '#333333',  # Same as Coal, with a patent finish\n",
    "    'White Satin': '#fffff0',  # Ivory, close to White Satin Lace\n",
    "    'Latte Patent': '#c5a883',  # Patent finish of Latte\n",
    "    'Navy Leather': '#000080',  # Navy blue\n",
    "    'Clear/Sand ': '#f4a460',  # Sandy brown, clear implied in product type\n",
    "    'White Crystal Bow': '#ffffff',  # White with crystal implied\n",
    "    'White Satin Pearl': '#fffff0',  # Ivory, close to White Satin\n",
    "    'Sand Transparent Rhinestone': '#c2b280',  # Light brown, transparent implied\n",
    "    'Coal Braid': '#333333',  # Same as Coal\n",
    "    'Sand Patent': '#f4a460',  # Light brown-yellow, as requested\n",
    "    'White': '#ffffff',\n",
    "    'Coal Canvas': '#333333',  # Same as Coal\n",
    "    'Mango Leather': '#FFC107',  # Bright yellow-orange\n",
    "    'Latte Braid': '#c5a883',  # Same as Latte\n",
    "    'Lavender Braid': '#e6e6fa',  # Light purple, similar to Lavender\n",
    "    'Mango Canvas': '#FFC107',  # Same as Mango Leather\n",
    "    'Cocoa Patent': '#d2691e',  # Chocolate brown, patent implied\n",
    "    'Sand Patent Bow': '#f4a460',  # Sandy brown, patent finish\n",
    "    'Lavender': '#e6e6fa',\n",
    "    'White Satin Bow': '#fffff0',  # Ivory, satin bow implied\n",
    "    'Ivory Satin Bow': '#fffff0',  # Ivory, similar to White Satin Bow\n",
    "    'Orchid': '#da70d6',\n",
    "    'Mango Elastic': '#FFC107',  # Bright yellow-orange\n",
    "    'White Canvas': '#ffffff',  # White, canvas texture implied\n",
    "    'Burgundy Velvet': '#800020',  # Deep red\n",
    "    'Blue Denim Daisy': '#1f75fe',  # Bright blue, denim implied\n",
    "    'Matte Gold': '#d4af37',  # Gold, matte finish\n",
    "    'Coal Patent Coal Rhinestone': '#333333',  # Coal, patent with rhinestone\n",
    "    'Taupe Blush Suede': '#b38b6d',  # Taupe Blush, suede finish\n",
    "    'Coal Crystal': '#333333',  # Coal, crystal finish implied\n",
    "    'Metallic Gold': '#d4af37',  # Bright gold, metallic finish\n",
    "}\n",
    "df_line = pd.read_csv(\"Line_item.csv\")\n",
    "#df_line.head()\n",
    "\n",
    "# Identify unique lineitem_type values\n",
    "unique_types = df_line['Item_Type'].unique()\n",
    "unique_types\n",
    "\n",
    "\n",
    "# Create a dictionary to hold the DataFrames for each lineitem_type\n",
    "dfs = {}\n",
    "\n",
    "for lineitem_type in unique_types:\n",
    "    # Filter the DataFrame for each unique lineitem_type and store it in the dictionary\n",
    "    dfs[lineitem_type] = df_line[df_line['Item_Type'] == lineitem_type]\n",
    "\n",
    "#dfs['Accessories'].head(5)\n",
    "\n",
    "dfs['Accessories']['Lineitem_name'].count()\n",
    "\n",
    "df_accessories = dfs['Accessories']\n",
    "\n",
    "df_acc_block = df_accessories[df_accessories['Lineitem_name'].str.contains('block', case=False)]\n",
    "\n",
    "# df_acc_block.to_csv('/content/sorted__acc_Line_item.csv')\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "#print(df_acc_block.head())\n",
    "\n",
    "df_acc_stiletto = df_accessories[df_accessories['Lineitem_name'].str.contains('stiletto', case=False)]\n",
    "\n",
    "# df_acc_stiletto.to_csv('/content/sorted__acc_stiletto.csv')\n",
    "\n",
    "# Display the first few rows of the filtered DataFrame\n",
    "#print(df_acc_stiletto.head())\n",
    "\n",
    "df_combo = dfs['combo']\n",
    "#df_combo.head()\n",
    "\n",
    "# Define a regex pattern to capture the Lineitem, Color, Accessories, and Size\n",
    "pattern = r'(.*) - (.+?) \\+ (.+?) - (\\d+\\.\\d+|\\d+)'\n",
    "\n",
    "df_combo[['Lineitem', 'Color', 'Accessories', 'Size']] = df_combo['Lineitem_name'].str.extract(pattern)\n",
    "\n",
    "#df_combo.head(5)\n",
    "\n",
    "#df_combo.info()\n",
    "\n",
    "df_coverage = dfs['Coverage']\n",
    "#df_coverage.head()\n",
    "\n",
    "# Regular expression pattern to match the price\n",
    "pattern = r'\\$(\\d+\\.\\d{2})'\n",
    "\n",
    "# Extract the price and assign it to a new column 'Price'\n",
    "df_coverage['Price'] = df_coverage['Lineitem_name'].str.extract(pattern)\n",
    "\n",
    "#print(df_coverage.head())\n",
    "\n",
    "# Convert both columns to a common type (string) for comparison, in case they are different types\n",
    "df_coverage['Price'] = df_coverage['Price'].astype(str)\n",
    "df_coverage['Lineitem_price'] = df_coverage['Lineitem_price'].astype(str)\n",
    "\n",
    "# Create a new column to indicate if the values in the two columns are identical\n",
    "df_coverage['is_identical'] = df_coverage['Price'] == df_coverage['Lineitem_price']\n",
    "\n",
    "# Check if all values are True (identical)\n",
    "all_identical = df_coverage['is_identical'].all()\n",
    "\n",
    "# Print the result and the DataFrame for verification\n",
    "#print(f\"All values are identical: {all_identical}\")\n",
    "#print(df_coverage[['Price', 'Lineitem_price', 'is_identical']].head(10))\n",
    "\n",
    "df_heel_kits = dfs['Heel']\n",
    "#df_heel_kits.head()\n",
    "\n",
    "# Filter the DataFrame to only include rows where Item_Type is 'Heel'\n",
    "df_heel_kits= df_heel_kits[df_heel_kits['Item_Type'] == 'Heel']\n",
    "\n",
    "# Define a function to categorize the heels based on keywords in 'Lineitem_name'\n",
    "def categorize_heels(name):\n",
    "    if 'Block' in name:\n",
    "        return 'Block Heel'\n",
    "    elif 'Stiletto' in name:\n",
    "        return 'Stiletto Heel'\n",
    "    # Add more conditions as needed for different types\n",
    "    else:\n",
    "        return 'Other Type'\n",
    "\n",
    "# Apply the categorization function to the 'Lineitem_name' column\n",
    "df_heel_kits['Heel_Category'] = df_heel_kits['Lineitem_name'].apply(categorize_heels)\n",
    "\n",
    "# Now df_heels includes a new column 'Heel_Category' with the type of heel kit\n",
    "#df_heel_kits.head()\n",
    "\n",
    "df_sandals = dfs['Sandals']\n",
    "#df_sandals.head()\n",
    "\n",
    "# Here we define two regex patterns for the two different types of line item names\n",
    "pattern1 = r'(.*) - (.*) - (\\d+)'\n",
    "pattern2 = r'(.*) - (.*) \\+ (.*) - (\\d+\\.?\\d*)'\n",
    "\n",
    "# Function to apply the regular expressions\n",
    "def extract_info(row):\n",
    "    if '+' in row['Lineitem_name']:\n",
    "        matches = re.match(pattern2, row['Lineitem_name'])\n",
    "        if matches:\n",
    "            return pd.Series([matches.group(1), matches.group(2), matches.group(3), matches.group(4)],\n",
    "                             index=['Shoes', 'Color', 'Added_item', 'Size'])\n",
    "        else:\n",
    "            return pd.Series([None, None, None, None], index=['Shoes', 'Color', 'Added_item', 'Size'])\n",
    "    else:\n",
    "        matches = re.match(pattern1, row['Lineitem_name'])\n",
    "        if matches:\n",
    "            return pd.Series([matches.group(1), matches.group(2), None, matches.group(3)],\n",
    "                             index=['Shoes', 'Color', 'Added_item', 'Size'])\n",
    "        else:\n",
    "            return pd.Series([None, None, None, None], index=['Shoes', 'Color', 'Added_item', 'Size'])\n",
    "\n",
    "# Apply the function to the DataFrame\n",
    "df_sandals[['Shoes', 'Color', 'Added_item', 'Size']] = df_sandals.apply(extract_info, axis=1)\n",
    "#df_sandals.head()\n",
    "\n",
    "subset = df_sandals[['Shoes', 'Color','Added_item','Size']]\n",
    "#subset.head()\n",
    "\n",
    "df_sandals['Shoes'].unique()\n",
    "#print(len(df_sandals['Shoes'].unique()))\n",
    "\n",
    "#df_sandals.info()\n",
    "#df_combo.head()\n",
    "\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Clean the data: Convert all line items to strings and handle NaNs\n",
    "df_combo['Lineitem'] = df_combo['Lineitem'].astype(str).fillna('Unknown')\n",
    "\n",
    "# Grouping the data by Order_Id and collecting Lineitems in each order\n",
    "orders_lineitems = df_combo.groupby('Order_ID')['Lineitem'].apply(list)\n",
    "\n",
    "# Initialize a counter for lineitem pairs\n",
    "lineitem_pairs = Counter()\n",
    "\n",
    "for lineitems in orders_lineitems:\n",
    "    # Ensure all items in lineitems are strings to avoid the TypeError\n",
    "    lineitems_str = [str(item) for item in lineitems]\n",
    "    for pair in combinations(set(lineitems_str), 3):\n",
    "        sorted_pair = tuple(sorted(pair))\n",
    "        lineitem_pairs[sorted_pair] += 1\n",
    "\n",
    "# Convert the lineitem pairs counter to a DataFrame for easier analysis\n",
    "lineitem_pairs_df = pd.DataFrame(lineitem_pairs.items(), columns=['Lineitem Pair', 'Frequency'])\n",
    "\n",
    "# Display the top 10 most common lineitem pairs\n",
    "top_lineitem_pairs = lineitem_pairs_df.sort_values('Frequency', ascending=False).head(10)\n",
    "#print(top_lineitem_pairs)\n",
    "\n",
    "# Split 'Lineitem Pair' into three separate columns\n",
    "lineitem_pairs_df[['Product1', 'Product2', 'Product3']] = pd.DataFrame(lineitem_pairs_df['Lineitem Pair'].tolist(), index=lineitem_pairs_df.index)\n",
    "\n",
    "# Drop the original 'Lineitem Pair' column\n",
    "lineitem_pairs_df.drop(columns=['Lineitem Pair'], inplace=True)\n",
    "\n",
    "# Sort the DataFrame by 'Frequency' to get the top combinations\n",
    "lineitem_pairs_df = lineitem_pairs_df.sort_values('Frequency', ascending=False)\n",
    "\n",
    "# Display the modified DataFrame (top 10)\n",
    "#print(lineitem_pairs_df.head(10))\n",
    "\n",
    "# Create a new column 'Combination' for plotting\n",
    "lineitem_pairs_df['Combination'] = lineitem_pairs_df[['Product1', 'Product2', 'Product3']].agg(' | '.join, axis=1)\n",
    "\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import plotly.express as px\n",
    "\n",
    "# Generate the (lineitem, accessory) pairs and count their frequencies\n",
    "item_accessory_pairs = Counter(zip(df_combo['Lineitem'], df_combo['Accessories']))\n",
    "\n",
    "# Initialize an empty list to hold the lineitem, accessory, and frequency\n",
    "item_accessory_pairs_list = []\n",
    "\n",
    "for (lineitem, accessory), frequency in item_accessory_pairs.items():\n",
    "    item_accessory_pairs_list.append({'Lineitem': lineitem, 'Accessories': accessory, 'Frequency': frequency})\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "item_accessory_pairs_df = pd.DataFrame(item_accessory_pairs_list)\n",
    "\n",
    "# Display the top 10 most common 'Lineitem'-'Accessory' pairs\n",
    "top_item_accessory_pairs = item_accessory_pairs_df.sort_values('Frequency', ascending=False).head(10)\n",
    "#print(top_item_accessory_pairs)\n",
    "\n",
    "df_combo['Lineitem'].unique()\n",
    "\n",
    "# Assuming 'df_combo' is loaded with relevant 'Lineitem' and 'Color' columns\n",
    "# Aggregate data to calculate frequency of each color for every lineitem\n",
    "color_frequency = df_combo.groupby(['Lineitem', 'Color']).size().reset_index(name='Frequency')\n",
    "\n",
    "# Sort the results to make sure the most frequent colors are listed first for each lineitem\n",
    "color_frequency_sorted = color_frequency.sort_values(['Lineitem', 'Frequency'], ascending=[True, False])\n",
    "\n",
    "# Visualize the top N colors for each lineitem\n",
    "top_n_colors = 5\n",
    "top_colors_per_lineitem = color_frequency_sorted.groupby('Lineitem').head(top_n_colors)\n",
    "\n",
    "# Update the top_colors_per_lineitem DataFrame with the corresponding color codes\n",
    "top_colors_per_lineitem['Color_Code'] = top_colors_per_lineitem['Color'].map(color_map)\n",
    "\n",
    "# Aggregate data to calculate frequency of each size for every lineitem\n",
    "size_frequency = df_combo.groupby(['Lineitem', 'Size']).size().reset_index(name='Frequency')\n",
    "\n",
    "# Sort the results to make sure the most frequent sizes are listed first for each lineitem\n",
    "size_frequency_sorted = size_frequency.sort_values(['Lineitem', 'Frequency'], ascending=[True, False])\n",
    "\n",
    "# Visualize the top N sizes for each lineitem\n",
    "top_n_sizes = 5\n",
    "top_sizes_per_lineitem = size_frequency_sorted.groupby('Lineitem').head(top_n_sizes)\n",
    "\n",
    "numeric_sizes = pd.to_numeric(df_combo['Size'], errors='coerce').dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e5824e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Dash app\n",
    "app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8340407",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the layout of the dashboard\n",
    "app.layout = dbc.Container(style={'backgroundColor': '#f0f0f0'}, children=[\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.H1(\"Sales Dashboard\", style={'textAlign': 'center'})\n",
    "        ], width=12)\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='country-dropdown',\n",
    "                options=[{'label': 'ALL', 'value': 'ALL'}] + [{'label': country, 'value': country} for country in merged_df['Billing_Country'].unique()],\n",
    "                value='ALL',\n",
    "                placeholder=\"Select a country\",\n",
    "                style={'width': '100%'}\n",
    "            ),\n",
    "            dcc.Graph(id='sales-by-country-graph')\n",
    "        ], width=12)\n",
    "    ]),\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='province-dropdown',\n",
    "                options=[{'label': 'ALL', 'value': 'ALL'}] + [{'label': province, 'value': province} for province in provinces_list],\n",
    "                value='ALL',\n",
    "                placeholder=\"Select a province\",\n",
    "                style={'width': '100%'}\n",
    "            ),\n",
    "            dcc.Graph(id='sales-by-province-graph')\n",
    "        ], width=12)\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Dropdown(\n",
    "                id='payment-dropdown',\n",
    "                options=[{'label': 'ALL', 'value': 'ALL'}] + [{'label': payment, 'value': payment} for payment in merged_df['Payment_Method'].unique()],\n",
    "                value='ALL',\n",
    "                placeholder=\"Select a payment method\",\n",
    "                style={'width': '100%'}\n",
    "            ),\n",
    "            dcc.Graph(id='revenue-by-payment-method-graph')\n",
    "        ], width=12)\n",
    "    ]),\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Input(id='dummy-input', style={'display': 'none'}, value='dummy-value'),\n",
    "            dcc.Graph(id='revenue-by-item-type-pie-chart')\n",
    "        ], width=6),\n",
    "        dbc.Col([\n",
    "            dcc.Graph(id='marketing-yes-pie-chart')\n",
    "        ], width=6)\n",
    "    ]),\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Graph(id='orders-by-quarter-graph')\n",
    "        ], width=12)\n",
    "    ]),\n",
    "\n",
    "    # New components for \"Item Type Dashboard\"\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.H1(\"Item Type Dashboard\", style={'textAlign': 'center'})\n",
    "        ], width=12)\n",
    "    ]),\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Div([\n",
    "                dcc.Markdown('### Select Size'),  # Title for the RangeSlider\n",
    "                dcc.RangeSlider(\n",
    "                    id='size-range-slider',\n",
    "                    min=int(numeric_sizes.min()),\n",
    "                    max=int(numeric_sizes.max()),\n",
    "                    value=[int(numeric_sizes.min()), int(numeric_sizes.max())],\n",
    "                    marks={int(size): str(size)\n",
    "                           for size in range(int(numeric_sizes.min()), int(numeric_sizes.max()) + 1)},\n",
    "                    tooltip={\"placement\": \"bottom\", \"always_visible\": True}\n",
    "                )\n",
    "            ])\n",
    "        ], width=6),\n",
    "\n",
    "        dbc.Col([\n",
    "            html.Div([\n",
    "                dcc.Markdown('#### Select Line Item'),\n",
    "                dcc.Dropdown(\n",
    "                    id='line-item-dropdown',\n",
    "                    options=[{'label': 'All', 'value': 'All'}] + [{'label': lineitem, 'value': lineitem} for lineitem in df_combo['Lineitem'].unique()],\n",
    "                    value='All'  # Set default value to 'All'\n",
    "                )\n",
    "            ])\n",
    "        ], width=6)\n",
    "    ]),\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            dcc.Graph(id='size-revenue-graph', figure={})  # Placeholder, replace with your component\n",
    "        ], width=6),\n",
    "        dbc.Col([\n",
    "            dcc.Graph(id='revenue-graph', figure={})  # Placeholder, replace with your component\n",
    "        ], width=6),\n",
    "    ]),\n",
    "\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            html.Div([\n",
    "                dcc.Markdown('#### Select Color'),\n",
    "                dcc.Dropdown(\n",
    "                    id='color-dropdown',\n",
    "                    options=[{'label': 'All', 'value': 'All'}] + [{'label': color, 'value': color} for color in color_map.keys()],\n",
    "                    value='All'  # Set default value to 'All'\n",
    "                )\n",
    "            ])\n",
    "        ], width=6),\n",
    "\n",
    "        dbc.Col([\n",
    "            dcc.Graph(id='color-graph', figure={})  # Placeholder, replace with your component\n",
    "        ], width=12),\n",
    "    ]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f73886db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to update graph based on payment method selection\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('revenue-by-payment-method-graph', 'figure'),\n",
    "    [dash.dependencies.Input('payment-dropdown', 'value')]\n",
    ")\n",
    "def update_payment_graph(selected_payment_method):\n",
    "    if selected_payment_method == 'ALL':\n",
    "        payment_data = merged_df\n",
    "    else:\n",
    "        payment_data = merged_df[merged_df['Payment_Method'] == selected_payment_method]\n",
    "\n",
    "    revenue_by_payment_method = payment_data.groupby('Payment_Method')['Total'].sum().reset_index()\n",
    "    sorted_revenue = revenue_by_payment_method.sort_values(by='Total', ascending=False)\n",
    "\n",
    "    # Select only the top 10 payment methods\n",
    "    top_10_revenue = sorted_revenue.head(10)\n",
    "\n",
    "    data_p = [\n",
    "        go.Bar(\n",
    "            x=top_10_revenue['Payment_Method'],\n",
    "            y=top_10_revenue['Total']\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title='Revenue by Payment Method (Top 10)',\n",
    "        xaxis=dict(title='Payment Method', tickangle=45),\n",
    "        yaxis=dict(title='Revenue'),\n",
    "        margin=dict(b=150)\n",
    "    )\n",
    "\n",
    "    return {'data': data_p, 'layout': layout}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38266163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to update graph based on dropdown selection\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('sales-by-country-graph', 'figure'),\n",
    "    [dash.dependencies.Input('country-dropdown', 'value')]\n",
    ")\n",
    "def update_graph(selected_country):\n",
    "    if selected_country == 'ALL':\n",
    "        sorted_top_10_df = top_10_df.sort_values(by='Total Sales', ascending=True)\n",
    "        data_c = [\n",
    "            go.Bar(\n",
    "                y=sorted_top_10_df['Country'],\n",
    "                x=sorted_top_10_df['Total Sales'],\n",
    "                orientation='h'\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        country_data = merged_df[merged_df['Billing_Country'] == selected_country]\n",
    "        country_sales = country_data.groupby('Billing_Country')['Total'].sum().reset_index()\n",
    "        data_c = [\n",
    "            go.Bar(\n",
    "                y=country_sales['Billing_Country'],\n",
    "                x=country_sales['Total'],\n",
    "                orientation='h'\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title='Sales by Country',\n",
    "        yaxis=dict(title='Country'),\n",
    "        xaxis=dict(title='Total Sales')\n",
    "    )\n",
    "\n",
    "    return {'data': data_c, 'layout': layout}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd5db7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to update graph based on province selection\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('sales-by-province-graph', 'figure'),\n",
    "    [dash.dependencies.Input('province-dropdown', 'value')]\n",
    ")\n",
    "def update_province_graph(selected_province):\n",
    "    if selected_province == 'ALL':\n",
    "        data_s = [\n",
    "            go.Bar(\n",
    "                y=top_10_regions['Region'],\n",
    "                x=top_10_regions['Total'],\n",
    "                orientation='h'\n",
    "            )\n",
    "        ]\n",
    "    else:\n",
    "        province_data = top_10_regions[top_10_regions['Billing_Province'] == selected_province]\n",
    "        province_sales = province_data.groupby('Region')['Total'].sum().reset_index()\n",
    "        sorted_province_sales = province_sales.sort_values(by='Total', ascending=False)\n",
    "        data_s = [\n",
    "            go.Bar(\n",
    "                y=sorted_province_sales['Region'],\n",
    "                x=sorted_province_sales['Total'],\n",
    "                orientation='h'\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title='Sales by Province',\n",
    "        yaxis=dict(title='Region'),\n",
    "        xaxis=dict(title='Total Sales')\n",
    "    )\n",
    "\n",
    "    return {'data': data_s, 'layout': layout}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b9107a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callback to update pie chart based on revenue generated by item type\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('revenue-by-item-type-pie-chart', 'figure'),\n",
    "    [dash.dependencies.Input('dummy-input', 'value')]\n",
    ")\n",
    "def update_item_type_pie_chart(dummy_input):\n",
    "    revenue_by_item_type = line.groupby('Item_type')['Lineitem_price'].sum().reset_index()\n",
    "    #lineitem_df.groupby('Item_Type')['Lineitem_price'].sum().reset_index()\n",
    "\n",
    "    data_pc = [\n",
    "        go.Pie(\n",
    "            labels=revenue_by_item_type['Item_type'],\n",
    "            values=revenue_by_item_type['Lineitem_price']\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title='Revenue by Item Type'\n",
    "    )\n",
    "\n",
    "    return {'data': data_pc, 'layout': layout}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8fe60adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define callback to update pie chart based on percentage of users who say yes to marketing\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('marketing-yes-pie-chart', 'figure'),\n",
    "    [dash.dependencies.Input('dummy-input', 'value')]\n",
    ")\n",
    "def update_marketing_yes_pie_chart(dummy_input):\n",
    "    # Count the number of users who say yes and no to marketing\n",
    "    marketing_counts = merged_df['Accepts_Marketing'].value_counts()\n",
    "\n",
    "    # Calculate the percentage of users who say yes and no to marketing\n",
    "    total_users = marketing_counts.sum()\n",
    "    yes_percentage = (marketing_counts['yes'] / total_users) * 100\n",
    "    no_percentage = (marketing_counts['no'] / total_users) * 100\n",
    "\n",
    "    # Create the pie chart data\n",
    "    data_ypc = [\n",
    "        go.Pie(\n",
    "            labels=['Yes', 'No'],\n",
    "            values=[yes_percentage, no_percentage]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title='Percentage of Users Who Say Yes to Marketing'\n",
    "    )\n",
    "\n",
    "    return {'data': data_ypc, 'layout': layout}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77691df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define callback to update graph based on revenue generated per quarter\n",
    "@app.callback(\n",
    "    dash.dependencies.Output('orders-by-quarter-graph', 'figure'),\n",
    "    [dash.dependencies.Input('dummy-input', 'value')]  # Input to trigger callback, you can change this if needed\n",
    ")\n",
    "def update_orders_by_quarter(dummy_input):\n",
    "\n",
    "    data_q = [\n",
    "        go.Bar(\n",
    "            x=customers_per_quarter.index.strftime('%Y-Q%q'), #.index.strftime('%Y-Q%q'),\n",
    "            y=customers_per_quarter.values, #quarterly_revenue['Revenue'], #total_revenue.values\n",
    "            marker=dict(color='#1f77b4')\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    layout = go.Layout(\n",
    "        title='Orders placed by Quarter',\n",
    "        xaxis=dict(title='Quarter'),\n",
    "        yaxis=dict(title='Count of Orders'),\n",
    "        hovermode='closest',\n",
    "        plot_bgcolor='#f0f0f0',\n",
    "        paper_bgcolor='#f0f0f0'\n",
    "    )\n",
    "\n",
    "    return {'data': data_q, 'layout': layout}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "63563f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Callback to update the revenue pie chart based on selected line item\n",
    "@app.callback(\n",
    "    Output('revenue-graph', 'figure'),\n",
    "    Input('line-item-dropdown', 'value')\n",
    ")\n",
    "def update_revenue_graph(selected_line_item):\n",
    "    if selected_line_item == 'All':\n",
    "        filtered_data = df_combo  # Show all line items\n",
    "    else:\n",
    "        filtered_data = df_combo[df_combo['Lineitem'] == selected_line_item]\n",
    "\n",
    "    # Calculate total revenue generated by each line item\n",
    "    revenue_by_lineitem = filtered_data.groupby('Lineitem').agg({'Lineitem_price': 'sum'}).reset_index()\n",
    "    revenue_by_lineitem['Tooltip_Text'] = 'Line Item: ' + revenue_by_lineitem['Lineitem'] + '<br>' + \\\n",
    "                                           'Revenue: $' + revenue_by_lineitem['Lineitem_price'].astype(str)\n",
    "\n",
    "    fig = px.pie(revenue_by_lineitem,\n",
    "                 values='Lineitem_price',\n",
    "                 names='Lineitem',\n",
    "                 title='Total Revenue Generated by Line Item',\n",
    "                 labels={'Lineitem_price': 'Revenue'},\n",
    "                 custom_data=['Tooltip_Text'])\n",
    "\n",
    "    fig.update_traces(hovertemplate='%{customdata[0]}')\n",
    "\n",
    "    # Highlight the selected slice if a line item is chosen\n",
    "    if selected_line_item != 'All':\n",
    "        # Find the index of the selected line item in the dataframe\n",
    "        selected_index = revenue_by_lineitem[revenue_by_lineitem['Lineitem'] == selected_line_item].index[0]\n",
    "        # Create a list to store pull values for each slice\n",
    "        pulls = [0.1 if i == selected_index else 0 for i in range(len(revenue_by_lineitem))]\n",
    "        fig.update_traces(pull=pulls)\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "329bc85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Callback to update the size order count graph based on selected size range\n",
    "@app.callback(\n",
    "    Output('size-revenue-graph', 'figure'),\n",
    "    [Input('size-range-slider', 'value')]\n",
    ")\n",
    "def update_size_revenue_graph(size_range):\n",
    "    # Convert 'Size' column to numeric type\n",
    "    df_combo['Size'] = pd.to_numeric(df_combo['Size'], errors='coerce')\n",
    "\n",
    "    # Filter data based on selected size range\n",
    "    filtered_data = df_combo[(df_combo['Size'] >= size_range[0]) & (df_combo['Size'] <= size_range[1])]\n",
    "\n",
    "    # Calculate total number of orders for each size\n",
    "    order_count_by_size = filtered_data.groupby('Size').size().reset_index(name='Order_Count')\n",
    "\n",
    "    fig = px.bar(order_count_by_size,\n",
    "                 x='Size',\n",
    "                 y='Order_Count',\n",
    "                 title='Order Count by Size',\n",
    "                 labels={'Order_Count': 'Order Count', 'Size': 'Size'})\n",
    "\n",
    "    # Add a line graph overlay\n",
    "    fig.add_trace(go.Scatter(x=order_count_by_size['Size'],\n",
    "                             y=order_count_by_size['Order_Count'],\n",
    "                             mode='lines',\n",
    "                             name='Trends',\n",
    "                             hoverinfo='skip'))\n",
    "\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "596ad23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Callback to update the graph for the 'Colors' tab\n",
    "@app.callback(\n",
    "    Output('color-graph', 'figure'),\n",
    "    Input('color-dropdown', 'value')\n",
    ")\n",
    "def update_color_graph(selected_color):\n",
    "    if selected_color == 'All':\n",
    "        # Show all colors\n",
    "        fig = px.bar(color_frequency_sorted,\n",
    "                     x='Lineitem',\n",
    "                     y='Frequency',\n",
    "                     color='Color',\n",
    "                     color_discrete_map=color_map,\n",
    "                     title='Most Favorite Colors for Each Lineitem',\n",
    "                     labels={'Frequency': 'Frequency of Color'},\n",
    "                     category_orders={\"Lineitem\": color_frequency_sorted['Lineitem'].unique()})\n",
    "    else:\n",
    "        # Filter data based on selected color\n",
    "        filtered_data = color_frequency_sorted[color_frequency_sorted['Color'] == selected_color]\n",
    "        fig = px.bar(filtered_data,\n",
    "                     x='Lineitem',\n",
    "                     y='Frequency',\n",
    "                     color='Color',\n",
    "                     color_discrete_map=color_map,\n",
    "                     title=f'Most Favorite Colors for Each Lineitem - {selected_color}',\n",
    "                     labels={'Frequency': 'Frequency of Color'},\n",
    "                     category_orders={\"Lineitem\": color_frequency_sorted['Lineitem'].unique()})\n",
    "\n",
    "    fig.update_layout(xaxis={'categoryorder': 'total descending'})\n",
    "    return fig\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a58f6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fa4c6288af0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True,port=8050)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
